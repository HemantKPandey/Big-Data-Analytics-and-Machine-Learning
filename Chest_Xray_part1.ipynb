{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "'''\n",
    "Last amended: 25th Nov, 2018\n",
    "Ref: Page 143 (Section 5.3) of Book 'Deep Learning with python'\n",
    "     by Francois Chollet\n",
    "\n",
    "Objective:\n",
    "         Transfer Learning: Building powerful image classification\n",
    "                            models using very little data using\n",
    "                            pre-trained applications\n",
    " Here we intend to find the possible cases if Pneumonia, in early stages by analysing Chest X\n",
    " rays of Patients available on Kaggle with help of  Image processing using Python for \n"
    " Big Data Analytics methods for Classifications.\n",
    "Steps:\n",
    "\t1. Create higher level abstract features from train data\n",
    "       and save these to file\n",
    "\t2. Used saved features as input to a FC model to make predictions\n",
    "    3. Save FC model\n",
    "    4. Use the complete model to make predictions\n",
    "\n",
    "Data from Kaggle: https://www.kaggle.com/paultimothymooney/chest-xray-pneumonia\n",
    "\n",
    "In our setup, we:\n",
    "- created a folder: /home/ashok/Images/chest_xray/\n",
    "- created train/,test/ and val/ subfolders inside chest_xray/\n",
    "- created Normal/ and PNEUMONIA/ subfolders inside train/ and val/\n",
    "\n",
    "In summary, this is our directory structure:\n",
    "'''\n",
    "Images/\n",
    "\tdata/\n",
    "\t    train/\n",
    "        \tNormal/\n",
    "        \t    IM-0115-0001.jpg\n",
    "        \t    IM-0117-0001.jpg\n",
    "        \t    ...\n",
    "        \tPNEUMONIA/\n",
    "        \t    person1_bacteria_1.jpg\n",
    "        \t    person1_bacteria_2.jpg\n",
    "        \t    ...\n",
    "\t    val/\n",
    "        \tNormal/\n",
    "        \t    NORMAL2-IM-1427-0001.jpeg\n",
    "        \t    NORMAL2-IM-1430-0001.jpeg\n",
    "        \t    ...\n",
    "        \tPNEUMONIA/\n",
    "        \t    person1946_bacteria_4874.jpeg\n",
    "        \t    person1946_bacteria_4875.jpeg\n",
    "\n",
    "\t$ source activate tensorflow\n",
    "\t$ jupyter notebook\n",
    "\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####********************************************************************************\n",
    "#### *****************   PART I: Tranform train data to abstract features and save**\n",
    "####********************************************************************************"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%reset -f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ashok/anaconda3/envs/tensorflow/lib/python3.5/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "## 1. Call libraries\n",
    "import numpy as np\n",
    "\n",
    "# 1.1 Classes for creating models\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dropout, Flatten, Dense\n",
    "\n",
    "# 1.2 Class for accessing pre-built models\n",
    "from keras import applications\n",
    "\n",
    "# 1.3 Class for generating infinite images\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "# 1.4 Miscelleneous\n",
    "import time, os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "############################# AA. Constants & Hyperparameters ###################3\n",
    "## 2. Constants/hyperparameters\n",
    "\n",
    "# 2.1 Where are cats and dogs?\n",
    "train_data_dir      =  '/home/ashok/Images/chest_xray/train'\n",
    "validation_data_dir =  '/home/ashok/Images/chest_xray/val'\n",
    "test_data_dir = '/home/ashok/Images/chest_xray/test'\n",
    "\n",
    "# 2.2 Constrain dimensions of our images\n",
    "#     during image generation\n",
    "img_width, img_height = 88,70       # Small size images for modeling speed; (1776, 1416)\n",
    "\n",
    "\n",
    "# 2.3 How many of them?\n",
    "nb_train_samples, nb_validation_samples,nb_test_samples = 5216,16,624 #(1341+3875,8+8,234+390)\n",
    "\n",
    "\n",
    "# 2.4 Predict in batches that fit RAM\n",
    "#     and also sample-size is fully divisible by it\n",
    "batch_size = 32         # Maybe for 4GB machine, batch-size of 32 will be OK\n",
    "\n",
    "\n",
    "# 2.5 File to which transformed bottleneck features for train data wil be stored\n",
    "bf_filename = '/home/ashok/.keras/models/bottleneck_features_train.npy'\n",
    "\n",
    "# 2.6 File to which transformed bottleneck features for validation data wil be stored\n",
    "val_filename = '/home/ashok/.keras/models/bottleneck_features_validation.npy'\n",
    "\n",
    "# 2.6 File to which transformed bottleneck features for validation data wil be stored\n",
    "test_filename = '/home/ashok/.keras/models/bottleneck_features_test.npy'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 5216 images belonging to 2 classes.\n",
      "Found 16 images belonging to 2 classes.\n",
      "Found 624 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "############################# BB. Data Generation ###################3\n",
    "\n",
    "## 3. Data augmentation (sort of)\n",
    "\n",
    "# 3.1 Instanstiate an image data generator: Needd to feed into the model\n",
    "#     Only normalization & nothing else like flipping, rotation etc; just to\n",
    "#     keep things simple.\n",
    "\n",
    "datagen_train = ImageDataGenerator(rescale=1. / 255)\n",
    "\n",
    "# 3.2 Configure datagen_train further\n",
    "#     Datagenerator is configured twice. First configuration\n",
    "#    is about image manipulation features\n",
    "#    IInd configuration is regarding data source, data classes, batchsize  etc\n",
    "\n",
    "generator_tr = datagen_train.flow_from_directory(\n",
    "              directory = train_data_dir,\t\t      # Path to target train directory.\n",
    "              target_size=(img_width, img_height),    # Dimensions to which all images will be resized.\n",
    "              batch_size=batch_size,                  # At a time so many images will be output\n",
    "              class_mode=None,                        # Return NO labels along with image data\n",
    "              shuffle=False                           # Default shuffle = True\n",
    "                                                      # Now images are picked up first from\n",
    "                                                      #  one folder then from another; no shuffling\n",
    "                                                      #   We will be using images NOT for\n",
    "                                                      #    learning any model but only for prediction\n",
    "                                                      #      so shuffle = False is OK as we now know\n",
    "                                                      #       that Ist 1000 images are of one kind\n",
    "                                                      #        and next 1000 images of another kind\n",
    "                                                      # See: https://github.com/keras-team/keras/issues/3296\n",
    "              )\n",
    "\n",
    "# 3.3. Generator for validation data.\n",
    "#      Initialize ImageDataGenerator object once more\n",
    "datagen_val = ImageDataGenerator(rescale=1. / 255)\n",
    "generator_val = datagen_val.flow_from_directory(\n",
    "                                          validation_data_dir,\n",
    "                                          target_size=(img_width, img_height),\n",
    "                                          batch_size=batch_size,\n",
    "                                          class_mode=None,\n",
    "                                          shuffle=False   # Default shuffle = True\n",
    "                                                      # Now images are picked up first from\n",
    "                                                      #  one folder then from another; no shuffling\n",
    "                                                      #   We will be using images NOT for\n",
    "                                                      #    learning any model but only for prediction\n",
    "                                                      #      so shuffle = False is OK as we now know\n",
    "                                                      #       that Ist 1000 images are of one kind\n",
    "                                                      #        and next 1000 images of another kind\n",
    "                                                      # See: https://github.com/keras-team/keras/issues/3296\n",
    "                                          )\n",
    "# 5.1 Generator for test data.\n",
    "#      Initialize ImageDataGenerator object once more\n",
    "datagen_ts = ImageDataGenerator(rescale=1. / 255)\n",
    "generator_ts = datagen_ts.flow_from_directory(\n",
    "                                          test_data_dir,\n",
    "                                          target_size=(img_width, img_height),\n",
    "                                          batch_size=batch_size,\n",
    "                                          class_mode=None,\n",
    "                                          shuffle=False \n",
    "                                          )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ########################## CC. Modeling & Feature creation #####################\n",
    "### #########################For both train and validation data ####################\n",
    "### #################Created features become our fresh train/validation data########"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         (None, 88, 70, 3)         0         \n",
      "_________________________________________________________________\n",
      "block1_conv1 (Conv2D)        (None, 88, 70, 64)        1792      \n",
      "_________________________________________________________________\n",
      "block1_conv2 (Conv2D)        (None, 88, 70, 64)        36928     \n",
      "_________________________________________________________________\n",
      "block1_pool (MaxPooling2D)   (None, 44, 35, 64)        0         \n",
      "_________________________________________________________________\n",
      "block2_conv1 (Conv2D)        (None, 44, 35, 128)       73856     \n",
      "_________________________________________________________________\n",
      "block2_conv2 (Conv2D)        (None, 44, 35, 128)       147584    \n",
      "_________________________________________________________________\n",
      "block2_pool (MaxPooling2D)   (None, 22, 17, 128)       0         \n",
      "_________________________________________________________________\n",
      "block3_conv1 (Conv2D)        (None, 22, 17, 256)       295168    \n",
      "_________________________________________________________________\n",
      "block3_conv2 (Conv2D)        (None, 22, 17, 256)       590080    \n",
      "_________________________________________________________________\n",
      "block3_conv3 (Conv2D)        (None, 22, 17, 256)       590080    \n",
      "_________________________________________________________________\n",
      "block3_pool (MaxPooling2D)   (None, 11, 8, 256)        0         \n",
      "_________________________________________________________________\n",
      "block4_conv1 (Conv2D)        (None, 11, 8, 512)        1180160   \n",
      "_________________________________________________________________\n",
      "block4_conv2 (Conv2D)        (None, 11, 8, 512)        2359808   \n",
      "_________________________________________________________________\n",
      "block4_conv3 (Conv2D)        (None, 11, 8, 512)        2359808   \n",
      "_________________________________________________________________\n",
      "block4_pool (MaxPooling2D)   (None, 5, 4, 512)         0         \n",
      "_________________________________________________________________\n",
      "block5_conv1 (Conv2D)        (None, 5, 4, 512)         2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv2 (Conv2D)        (None, 5, 4, 512)         2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv3 (Conv2D)        (None, 5, 4, 512)         2359808   \n",
      "_________________________________________________________________\n",
      "block5_pool (MaxPooling2D)   (None, 2, 2, 512)         0         \n",
      "=================================================================\n",
      "Total params: 14,714,688\n",
      "Trainable params: 14,714,688\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "163/163 [==============================] - 3176s 19s/step\n",
      "Time taken:  52.94323564370473 minutes\n"
     ]
    }
   ],
   "source": [
    "# 4. Buld VGG16 network model with 'imagenet' weights\n",
    "#     Do not include the top FC layer of VGG16 model\n",
    "#      Weights will be downloaded, if absent\n",
    "model = applications.VGG16(\n",
    "\t                       include_top=False,\n",
    "\t                       weights='imagenet',\n",
    "\t                       input_shape=(img_width, img_height,3)\n",
    "\t                       )\n",
    "model.summary()\n",
    "\n",
    "\n",
    "# 4.1 Feed images through VGG16 model in batches (steps)\n",
    "#     And make 'predictions'.\n",
    "#     Following takes time 7 +3 = 10 minutes\n",
    "#     Note that there is no need for 'fit' method as weights are\n",
    "#     already learnt\n",
    "\n",
    "start = time.time()\n",
    "# 4.1 By feeding the input samples from generator, create vgg16 output/predictions\n",
    "#     uptil the last layer. We call it 'bottleneck features' as it is not the desired\n",
    "#     end result\n",
    "#     steps:  How many batches of images to output\n",
    "bottleneck_features_train = model.predict_generator(\n",
    "                                                    generator = generator_tr,\n",
    "                                                    steps = nb_train_samples // batch_size,\n",
    "                                                    verbose = 1\n",
    "                                                    )\n",
    "end = time.time()\n",
    "print(\"Time taken: \",(end - start)/60, \"minutes\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time taken:  0.006626439094543457 minutes\n",
      "19/19 [==============================] - 410s 22s/step\n",
      "Time taken:  6.831612356503805 minutes\n"
     ]
    }
   ],
   "source": [
    "# 4.3   Similarly, make predictions for validation data and extract features\n",
    "#     Takes 12 minutes\n",
    "start = time.time()\n",
    "bottleneck_features_validation = model.predict_generator(\n",
    "                                                         generator = generator_val,\n",
    "                                                         steps = nb_validation_samples // batch_size,\n",
    "                                                         verbose = 1\n",
    "                                                         )\n",
    "\n",
    "end = time.time()\n",
    "print(\"Time taken: \",(end - start)/60, \"minutes\")\n",
    "\n",
    "# 4.3   Similarly, make predictions for test data and extract features\n",
    "#     Takes 12 minutes\n",
    "start = time.time()\n",
    "bottleneck_features_test = model.predict_generator(\n",
    "                                                         generator = generator_ts,\n",
    "                                                         steps = nb_test_samples // batch_size,\n",
    "                                                         verbose = 1\n",
    "                                                         )\n",
    "\n",
    "end = time.time()\n",
    "print(\"Time taken: \",(end - start)/60, \"minutes\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5. Save the train features\n",
    "# 5.1 First delete the file to whcih we will save\n",
    "\n",
    "if os.path.exists(bf_filename):\n",
    "    os.system('rm ' + bf_filename)\n",
    "\n",
    "# 5.2 Next save the train-features\n",
    "np.save(open(bf_filename, 'wb'), bottleneck_features_train)\n",
    "\n",
    "# 5.3 Save validation features from model\n",
    "if os.path.exists(val_filename):\n",
    "    os.system('rm ' + val_filename)\n",
    "\n",
    "np.save(open(val_filename, 'wb'), bottleneck_features_validation)\n",
    "\n",
    "# 5.3 Save test features from model\n",
    "if os.path.exists(test_filename):\n",
    "    os.system('rm ' + test_filename)\n",
    "\n",
    "np.save(open(test_filename, 'wb'), bottleneck_features_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 6.1 File to which FC model weights could be stored\n",
    "top_model_weights_path = '/home/ashok/.keras/models/bottleneck_fc_model.h5'\n",
    "# 6.2 Finally save model weights for later use\n",
    "model.save_weights(top_model_weights_path)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
