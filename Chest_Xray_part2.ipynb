{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ############### ########### ##################### #######\n",
    "#### ############### PART-II BEGIN AGAIN #####################\n",
    "#### ############### ########### ##################### #######"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ashok/anaconda3/envs/tensorflow/lib/python3.5/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "## Part II: Load saved abstract features and proceed\n",
    "#           with modeling and prediction\n",
    "\n",
    "# 1.0 Call libraries\n",
    "%reset -f\n",
    "import numpy as np\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dropout, Flatten, Dense\n",
    "from keras import applications\n",
    "import time, os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. Hyperparameters/Constants\n",
    "# 2.1 Dimensions of our images.\n",
    "img_width, img_height = 88,70  # 150, 150\n",
    "nb_train_samples = 5216\n",
    "nb_validation_samples = 16\n",
    "nb_test_samples= 624\n",
    "epochs = 50\n",
    "batch_size = 32\n",
    "\n",
    "\n",
    "#2 Files for start of Using learned model\n",
    "\n",
    "#Features Saved in files\n",
    "# Bottleneck features for train data\n",
    "bf_filename = '/home/ashok/.keras/models/bottleneck_features_train.npy'\n",
    "# Validation-bottleneck features filename\n",
    "val_filename = '/home/ashok/.keras/models/bottleneck_features_validation.npy'\n",
    "# test-bottleneck features filename\n",
    "test_filename = '/home/ashok/.keras/models/bottleneck_features_test.npy'\n",
    "\n",
    "\n",
    "# 2.2 File to which FC model weights could be stored\n",
    "top_model_weights_path = '/home/ashok/.keras/models/bottleneck_fc_model.h5'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5216, 2, 2, 512)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 3. Load first train features\n",
    "train_data_features = np.load(open(bf_filename,'rb'))\n",
    "\n",
    "# 3.1 Train lables. First half are of one kind and next half of other\n",
    "#     Remember we had put 'shuffle = False' in data generators\n",
    "#     1341 labels of one kind. Another 3875 labels of another kind\n",
    "train_labels = np.array([0] * 1341 + [1] * 3875)   \n",
    "\n",
    "# 3.2\n",
    "train_data_features.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0,)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 4. Validation features\n",
    "validation_data_features = np.load(open(val_filename,'rb'))\n",
    "\n",
    "# 4.2 Validation labels: half-half\n",
    "validation_labels = np.array([0] * 8 + [1] * 8)\n",
    "\n",
    "# 4.1\n",
    "validation_data_features.shape  ## Is not good  for use since the features shape is not proper."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(608, 2, 2, 512)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#5. test features\n",
    "test_data_features = np.load(open(test_filename,'rb'))\n",
    "\n",
    "# 5.2 test labels: \n",
    "test_labels = np.array([0] * 222 + [1] * 386)\n",
    "\n",
    "# 5.1\n",
    "test_data_features.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "flatten_1 (Flatten)          (None, 2048)              0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 256)               524544    \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 1)                 257       \n",
      "=================================================================\n",
      "Total params: 524,801\n",
      "Trainable params: 524,801\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# 6. Plan model with FC layers only\n",
    "#    We use transformed features as input to FC model instead of actual train data\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Flatten(input_shape=train_data_features.shape[1:]))     # (2, 2, 512)\n",
    "model.add(Dense(256, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "model.summary()\n",
    "\n",
    "# 6.1\n",
    "model.compile(\n",
    "              optimizer='rmsprop',\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['accuracy']\n",
    "              )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 5216 samples, validate on 608 samples\n",
      "Epoch 1/50\n",
      "5216/5216 [==============================] - 15s 3ms/step - loss: 0.2294 - acc: 0.9062 - val_loss: 0.8575 - val_acc: 0.7484\n",
      "Epoch 2/50\n",
      "5216/5216 [==============================] - 11s 2ms/step - loss: 0.1484 - acc: 0.9415 - val_loss: 0.4676 - val_acc: 0.8355\n",
      "Epoch 3/50\n",
      "5216/5216 [==============================] - 11s 2ms/step - loss: 0.1317 - acc: 0.9467 - val_loss: 1.1326 - val_acc: 0.7352\n",
      "Epoch 4/50\n",
      "5216/5216 [==============================] - 14s 3ms/step - loss: 0.1156 - acc: 0.9555 - val_loss: 1.0388 - val_acc: 0.7829\n",
      "Epoch 5/50\n",
      "5216/5216 [==============================] - 10s 2ms/step - loss: 0.1192 - acc: 0.9565 - val_loss: 0.9555 - val_acc: 0.7993\n",
      "Epoch 6/50\n",
      "5216/5216 [==============================] - 11s 2ms/step - loss: 0.1095 - acc: 0.9571 - val_loss: 0.6561 - val_acc: 0.8339\n",
      "Epoch 7/50\n",
      "5216/5216 [==============================] - 13s 3ms/step - loss: 0.1089 - acc: 0.9592 - val_loss: 1.6658 - val_acc: 0.7122\n",
      "Epoch 8/50\n",
      "5216/5216 [==============================] - 12s 2ms/step - loss: 0.1084 - acc: 0.9603 - val_loss: 1.0928 - val_acc: 0.7944\n",
      "Epoch 9/50\n",
      "5216/5216 [==============================] - 12s 2ms/step - loss: 0.1031 - acc: 0.9632 - val_loss: 0.8624 - val_acc: 0.8174\n",
      "Epoch 10/50\n",
      "5216/5216 [==============================] - 12s 2ms/step - loss: 0.1100 - acc: 0.9622 - val_loss: 1.2992 - val_acc: 0.7780\n",
      "Epoch 11/50\n",
      "5216/5216 [==============================] - 12s 2ms/step - loss: 0.1089 - acc: 0.9607 - val_loss: 0.8267 - val_acc: 0.8224\n",
      "Epoch 12/50\n",
      "5216/5216 [==============================] - 12s 2ms/step - loss: 0.1074 - acc: 0.9634 - val_loss: 1.2930 - val_acc: 0.7632\n",
      "Epoch 13/50\n",
      "5216/5216 [==============================] - 13s 2ms/step - loss: 0.1048 - acc: 0.9643 - val_loss: 1.4423 - val_acc: 0.7747\n",
      "Epoch 14/50\n",
      "5216/5216 [==============================] - 11s 2ms/step - loss: 0.1054 - acc: 0.9653 - val_loss: 1.0521 - val_acc: 0.8109\n",
      "Epoch 15/50\n",
      "5216/5216 [==============================] - 12s 2ms/step - loss: 0.1061 - acc: 0.9666 - val_loss: 1.3805 - val_acc: 0.7780\n",
      "Epoch 16/50\n",
      "5216/5216 [==============================] - 14s 3ms/step - loss: 0.1021 - acc: 0.9680 - val_loss: 1.2844 - val_acc: 0.8043\n",
      "Epoch 17/50\n",
      "5216/5216 [==============================] - 16s 3ms/step - loss: 0.1150 - acc: 0.9657 - val_loss: 1.9989 - val_acc: 0.7385\n",
      "Epoch 18/50\n",
      "5216/5216 [==============================] - 15s 3ms/step - loss: 0.1163 - acc: 0.9680 - val_loss: 1.9155 - val_acc: 0.7484\n",
      "Epoch 19/50\n",
      "5216/5216 [==============================] - 14s 3ms/step - loss: 0.1170 - acc: 0.9638 - val_loss: 1.4021 - val_acc: 0.8059\n",
      "Epoch 20/50\n",
      "5216/5216 [==============================] - 13s 2ms/step - loss: 0.1109 - acc: 0.9695 - val_loss: 0.9924 - val_acc: 0.8421\n",
      "Epoch 21/50\n",
      "5216/5216 [==============================] - 14s 3ms/step - loss: 0.1141 - acc: 0.9676 - val_loss: 2.4331 - val_acc: 0.7286\n",
      "Epoch 22/50\n",
      "5216/5216 [==============================] - 12s 2ms/step - loss: 0.1291 - acc: 0.9645 - val_loss: 1.9645 - val_acc: 0.7615\n",
      "Epoch 23/50\n",
      "5216/5216 [==============================] - 10s 2ms/step - loss: 0.1150 - acc: 0.9668 - val_loss: 1.7865 - val_acc: 0.7648\n",
      "Epoch 24/50\n",
      "5216/5216 [==============================] - 14s 3ms/step - loss: 0.1150 - acc: 0.9703 - val_loss: 2.0941 - val_acc: 0.7533\n",
      "Epoch 25/50\n",
      "5216/5216 [==============================] - 11s 2ms/step - loss: 0.1205 - acc: 0.9691 - val_loss: 1.6767 - val_acc: 0.7747\n",
      "Epoch 26/50\n",
      "5216/5216 [==============================] - 13s 2ms/step - loss: 0.1246 - acc: 0.9697 - val_loss: 1.1318 - val_acc: 0.8306\n",
      "Epoch 27/50\n",
      "5216/5216 [==============================] - 14s 3ms/step - loss: 0.1297 - acc: 0.9666 - val_loss: 3.4853 - val_acc: 0.6908\n",
      "Epoch 28/50\n",
      "5216/5216 [==============================] - 14s 3ms/step - loss: 0.1232 - acc: 0.9691 - val_loss: 1.7136 - val_acc: 0.8092\n",
      "Epoch 29/50\n",
      "5216/5216 [==============================] - 17s 3ms/step - loss: 0.1548 - acc: 0.9620 - val_loss: 1.9268 - val_acc: 0.7812\n",
      "Epoch 30/50\n",
      "5216/5216 [==============================] - 13s 3ms/step - loss: 0.1448 - acc: 0.9689 - val_loss: 1.8845 - val_acc: 0.7829\n",
      "Epoch 31/50\n",
      "5216/5216 [==============================] - 9s 2ms/step - loss: 0.1442 - acc: 0.9661 - val_loss: 2.9663 - val_acc: 0.7237\n",
      "Epoch 32/50\n",
      "5216/5216 [==============================] - 7s 1ms/step - loss: 0.1611 - acc: 0.9678 - val_loss: 2.7020 - val_acc: 0.7467\n",
      "Epoch 33/50\n",
      "5216/5216 [==============================] - 13s 2ms/step - loss: 0.1459 - acc: 0.9691 - val_loss: 1.5746 - val_acc: 0.8224\n",
      "Epoch 34/50\n",
      "5216/5216 [==============================] - 16s 3ms/step - loss: 0.1657 - acc: 0.9670 - val_loss: 1.8595 - val_acc: 0.8076\n",
      "Epoch 35/50\n",
      "5216/5216 [==============================] - 19s 4ms/step - loss: 0.1559 - acc: 0.9688 - val_loss: 2.1113 - val_acc: 0.7928\n",
      "Epoch 36/50\n",
      "5216/5216 [==============================] - 13s 2ms/step - loss: 0.1574 - acc: 0.9718 - val_loss: 1.6618 - val_acc: 0.8191\n",
      "Epoch 37/50\n",
      "5216/5216 [==============================] - 17s 3ms/step - loss: 0.1942 - acc: 0.9638 - val_loss: 2.8124 - val_acc: 0.7319\n",
      "Epoch 38/50\n",
      "5216/5216 [==============================] - 14s 3ms/step - loss: 0.1779 - acc: 0.9670 - val_loss: 2.3649 - val_acc: 0.7664\n",
      "Epoch 39/50\n",
      "5216/5216 [==============================] - 16s 3ms/step - loss: 0.1764 - acc: 0.9672 - val_loss: 3.6272 - val_acc: 0.7023\n",
      "Epoch 40/50\n",
      "5216/5216 [==============================] - 16s 3ms/step - loss: 0.1600 - acc: 0.9705 - val_loss: 2.1055 - val_acc: 0.8043\n",
      "Epoch 41/50\n",
      "5216/5216 [==============================] - 15s 3ms/step - loss: 0.1892 - acc: 0.9714 - val_loss: 2.4544 - val_acc: 0.7648\n",
      "Epoch 42/50\n",
      "5216/5216 [==============================] - 16s 3ms/step - loss: 0.1850 - acc: 0.9689 - val_loss: 3.9207 - val_acc: 0.6908\n",
      "Epoch 43/50\n",
      "5216/5216 [==============================] - 16s 3ms/step - loss: 0.1784 - acc: 0.9707 - val_loss: 2.1229 - val_acc: 0.8010\n",
      "Epoch 44/50\n",
      "5216/5216 [==============================] - 15s 3ms/step - loss: 0.1828 - acc: 0.9699 - val_loss: 3.0773 - val_acc: 0.7434\n",
      "Epoch 45/50\n",
      "5216/5216 [==============================] - 12s 2ms/step - loss: 0.1774 - acc: 0.9724 - val_loss: 2.1118 - val_acc: 0.8043\n",
      "Epoch 46/50\n",
      "5216/5216 [==============================] - 15s 3ms/step - loss: 0.1879 - acc: 0.9711 - val_loss: 3.6385 - val_acc: 0.7122\n",
      "Epoch 47/50\n",
      "5216/5216 [==============================] - 15s 3ms/step - loss: 0.1895 - acc: 0.9711 - val_loss: 2.9004 - val_acc: 0.7533\n",
      "Epoch 48/50\n",
      "5216/5216 [==============================] - 13s 2ms/step - loss: 0.2131 - acc: 0.9691 - val_loss: 2.0340 - val_acc: 0.8141\n",
      "Epoch 49/50\n",
      "5216/5216 [==============================] - 16s 3ms/step - loss: 0.2078 - acc: 0.9697 - val_loss: 2.4863 - val_acc: 0.7780\n",
      "Epoch 50/50\n",
      "5216/5216 [==============================] - 14s 3ms/step - loss: 0.2377 - acc: 0.9676 - val_loss: 2.1019 - val_acc: 0.8191\n",
      "Time taken:  11.253722584247589 minutes\n"
     ]
    }
   ],
   "source": [
    "# 6.3 Fit model and make predictions on validation dataset\n",
    "#     Takes 2 minutes\n",
    "#     Watch Validation loss and Validation accuracy (around 81%)\n",
    "start = time.time()\n",
    "model.fit(train_data_features, train_labels,\n",
    "           epochs=epochs,\n",
    "           batch_size=batch_size,\n",
    "           validation_data=(test_data_features, test_labels),\n",
    "           verbose =1\n",
    "           )\n",
    "end = time.time()\n",
    "print(\"Time taken: \",(end - start)/60, \"minutes\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 7. Finally save model weights for later use\n",
    "model.save_weights(top_model_weights_path)\n",
    "#######################################################"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The mean Validation Accuracy received by this model on Test data is 80 %.\n",
    "\n",
    "###### We have removed the Validation Model fitting since there are not a big number of validation features."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
